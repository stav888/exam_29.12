1 - 
A(1,1): sqrt((1-2)^2 + (1-1)^2) = sqrt(1+0) = 1.0
B(2,2): sqrt((2-2)^2 + (2-1)^2) = sqrt(0+1) = 1.0
C(4,4): sqrt((4-2)^2 + (4-1)^2) = sqrt(4+9) = 3.6

- A (1.0) - Cat
- B (1.0) - Dog
	= Tie
__________________________________________________

2 -
     pass fail
Pass  [8  2]
Fail  [3  7]
__________________________________________________

3 -
D. Weights learned during model training
__________________________________________________

4 -
	1. MSE
Errors: (1-1)=0, (3-3)=0, (5-5)=0, (9-7)=2
Squared errors: 0, 0, 0, 4
Sum = 4
MSE = 4÷4=1.0

	2. R²
avg of y (ŷ) = (1+3+5+9) ÷ 4 = 4.5
TSS:
(1-4.5)² = 12.25
(3-4.5)² = 2.25
(5-4.5)² = 0.25
(9-4.5)² = 20.25
TSS | 12.25 + 2.25 + 0.25 + 20.25 = 35
RSS | 4
R²  | 1 - (4 ÷ 35) = 0.886

	3. Adjusted R²
1 - [(1-R²)(n-1)/(n-p-1)]
= 1 - [(4/35)(3)/2] = 1 - (12/70) = 1 - (6/35) = 29/35 ≈ 0.829


n = 4
p = 1
Adjusted R² = 1 - [(1 - R²) × (n-1) ÷ (n-p-1)]
= 1 - [(1 - 0.886) × 3 ÷ 2]
= 1 - [0.114 × 1.5]
= 1 - 0.171
= 0.829


ŷ: [1 3 5 7]
__________________________________________________

5 -
Gini root = 1 - (4/8)² - (4/8)² = 1 - 0.25 - 0.25 = 0.5

S - success | F - Fail

A: x ≤ 2
Left: (2S,0F) Gini=0
Right: (2S,4F) Gini=0.444
Weighted = ((2/8)*0 + (6/8)*0.444 = 0.333)
Gain = (0.5 - 0.333 = 0.167)

B: x ≤ 3
Left: (3S,0F) Gini=0
Right: (1S,4F) Gini=0.36
Weighted = ((3/8)*0 + (5/8)*0.36 = 0.225)
Gain = (0.5 - 0.225 = 0.275)

C: x ≤ 4
Left: (3S,1F) Gini=0.375
Right: (1S,3F) Gini=0.375
Weighted = ((4/8)*0.375 + (4/8)*0.375 = 0.375)
Gain = (0.5 - 0.375 = 0.125)

D: x ≤ 7
Left: (3S,4F) Gini≈0.49
Right: (1S,0F) Gini=0
Weighted ≈ ((7/8)*0.49 + (1/8)*0 = 0.428)
Gain ≈ (0.5 - 0.428 = 0.072)

	Best (largest gain) = 0.275 ⇒ Option B (x ≤ 3)
__________________________________________________

6 -
z = w₀x₀ + w₁x₁

Where:
* w₀ = 2
* w₁ = -1
* Threshold = 70%
* Bias = 0

z = 2*1 + (-1)*1 + 0 = 1

p = 1 / (1 + e^(-1))
  = 1 / (1 + 0.3679)
  = 1 / 1.3679
  = 0.7311

0.7311 > 0.70 =		B. Above the threshold
__________________________________________________

7 -
* A = (1,1) → y = 10
* B = (2,2) → y = 20
* C = (4,4) → y = 40
 A new point is given:
* Q = (2,1)

d(Q,A) = sqrt((2-1)^2 + (1-1)^2) = sqrt(1 + 0) = 1  
d(Q,B) = sqrt((2-2)^2 + (1-2)^2) = sqrt(0 + 1) = 1
d(Q,C) = sqrt((2-4)^2 + (1-4)^2) = sqrt(4 + 9) = sqrt(13) = 3.6055

K = 2 nearest: A (10), B (20)

Predicted y = (y_A + y_B) ÷ 2 = (10 + 20) ÷ 2 = 15
__________________________________________________

8 -
Accuracy = (3 + 4 + 5) / (3 + 1 + 0 + 2 + 4 + 1 + 0 + 1 + 5)
         = 12 / 17
         = 0.7059 (70.59%)
__________________________________________________

9 -
B - Overfitting
__________________________________________________

10 -
= 1*2 + (-1)*1 + 2*1 + (-3)
= 2 - 1 + 2 - 3
= 0  -		 C. Point lies exactly on the surface
__________________________________________________

11 -
B. Error calculated using samples not selected in bootstrap sampling
__________________________________________________

12 -
50 - 22 = 28
22 - 18 = 4
18 - 17 = 1

Elbow = Degree 2 (B)
__________________________________________________

13 -
d(Q,A) = sqrt((2-1)^2 + (2-2)^2 + (2-1)^2)
       = sqrt(1 + 0 + 1)
       = sqrt(2)
       = 1.4142

d(Q,B) = sqrt((2-2)^2 + (2-0)^2 + (2-2)^2)
       = sqrt(0 + 4 + 0)
       = 2

d(Q,C) = sqrt((2-3)^2 + (2-3)^2 + (2-0)^2)
       = sqrt(1 + 1 + 4)
       = sqrt(6)
       = 2.4495

d(Q,D) = sqrt((2-0)^2 + (2-1)^2 + (2-3)^2)
       = sqrt(4 + 1 + 1)
       = sqrt(6)
       = 2.4495

	3 nearest: A (1.4142), B (2), C and D tie (2.4495)
__________________________________________________

14 -
y = [2,4,6]
ŷ = [3,5,4]

errors = [2-3, 4-5, 6-4] = [-1, -1, 2]
squared = [1, 1, 4]
MSE = (1 + 1 + 4) / 3 = 6/3 = 2
__________________________________________________

15 -
mean = (4+7+10+10+13+15+15+18+20+28) / 10
     = 140 / 10
     = 14

(x-mean) = [-10, -7, -4, -4, -1, 1, 1, 4, 6, 14]  
(x-mean)^2 = [100, 49, 16, 16, 1, 1, 1, 16, 36, 196]

sum = 100+49+16+16+1+1+1+16+36+196
    = 432

population variance = 432 / 10 = 43.2

population std = sqrt(43.2) = 6.5727
__________________________________________________

16 -
C. The data includes input features and known output labels
__________________________________________________

17 -
B. Regression predicts continuous values while classification predicts discrete classes
__________________________________________________

18 -
MSE = (2 × 5 + 8 × 4) / 10
= (10 + 32) / 10
= 42 / 10
= 4.2
	A. 4.2
__________________________________________________

19 -
C. Training is used to learn model parameters, test is used to evaluate performance on unseen data
__________________________________________________

20 -
C. Both classification and regression
__________________________________________________

21 -
[1, x, x^2]

For x = 4: [1, 4, 4*4] = [1, 4, 16]
For x = 8: [1, 8, 8*8] = [1, 8, 64]
For x = 10: [1, 10, 10*10] = [1, 10, 100]

answer	b - [1,4,16],[1,8,64],[1,10,100]
__________________________________________________

22 -
B. Increases model complexity and risk of overfitting
__________________________________________________

23 -
B) Adjusted R² penalizes models for adding features that do not improve the model significantly
__________________________________________________

24 -
C. A probability estimate
__________________________________________________

25 -
B. Accuracy
